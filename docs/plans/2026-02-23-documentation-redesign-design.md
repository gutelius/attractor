# Documentation Redesign Design

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Replace the flat reference-style user guide with a progressive, tutorial-driven documentation suite that serves a PM who authors pipelines to build software products end-to-end.

**Audience:** A PM who writes their own .dot pipelines, builds any kind of software, and is comfortable with terminals but isn't a daily coder. They need to learn pipeline design as a discipline, not just API methods.

**Architecture:** Four documents, each serving a different moment in the PM's workflow.

## Document Structure

| Document | File | Purpose | When they reach for it |
|----------|------|---------|----------------------|
| Tutorial | `docs/tutorial.md` | Walk through building a real product from zero to shipped | First time using Attractor |
| Cookbook | `docs/cookbook.md` | Copy-paste pipeline patterns for common scenarios | "How do I do X?" |
| Concepts | `docs/concepts.md` | Explain how Attractor thinks — graph execution, routing, context, fidelity | "Why does this behave this way?" |
| Reference | `docs/reference.md` | Every attribute, shape, condition operator, event, CLI flag | "What are the valid values for Y?" |

The existing `docs/user-guide.md` is replaced by these four. The README links to Tutorial as the entry point.

The three NLSpec files stay as-is — they're for implementors, not pipeline authors.

---

## Tutorial (`docs/tutorial.md`)

**Title:** "Building Your First Software Product with Attractor"

Follows one continuous project — a task management API — from idea to shipped product. Each chapter introduces exactly one new Attractor concept by solving a real problem.

### Chapters

1. **Installation & Setup** — install uv, clone repo, sync, verify `attractor --help`. Render a .dot file to SVG with Graphviz.

2. **Your First Pipeline** — 3-node linear pipeline (Start → Plan → Exit). Explains digraph, shapes (Mdiamond, Msquare, box), `goal`, `label`. Validate and dry-run.

3. **Adding Real Work** — expand to Start → Plan → Implement → Exit. Introduce `prompt` attribute with `$goal` variable expansion. Explain codergen handler and dry-run vs. real backends.

4. **Branching and Decisions** — add diamond Review node after Implement. Two outgoing edges with conditions. Explain condition expressions, outcome variable, edge selection.

5. **Human Review Gates** — replace diamond with hexagon (human gate). Explain interviewer pattern: pause, present choices from edge labels, wait for input. Run interactively.

6. **Iteration Loops** — "revise" edge from Review back to Plan. Explain loops, `max_retries`, `retry_target`. Cover `loop_restart` edges that reset pipeline state.

7. **Quality Gates and Evaluation** — add `goal_gate=true` to a critical node. Explain gate enforcement at exit, retry_target jump-back. Introduce LLM-as-judge pattern: use a stronger model to evaluate a weaker model's output. Multi-stage validation chains (lint → test → LLM review → human review).

8. **Parallel Work** — split Implement into three parallel branches (API, Frontend, Tests). Component shape (fan-out) and tripleoctagon (fan-in). Join policies, error policies, context clones.

9. **Tool Nodes** — parallelogram node that runs `pytest`. Explain `tool_command`, timeout, output in context.

10. **Model Stylesheet** — 8+ node pipeline. Stylesheet with `*` defaults, `.critical` class via subgraphs, `#NodeId` overrides. Specificity rules.

11. **Context and Fidelity** — data flow between nodes via Context store. Fidelity modes: full (expensive), compact, summary. `thread_id` for conversation continuity.

12. **Checkpoints and Recovery** — kill a running pipeline, resume from checkpoint. Walk through `attractor resume`. What gets saved vs. what doesn't.

13. **Running the HTTP Server** — `attractor serve`, submit via curl, stream SSE events. How a frontend or monitoring tool consumes events.

14. **From PRD to Product** — full lifecycle: PM writes a PRD, pipeline generates a design spec, human reviews it, implementation proceeds, automated tests validate, LLM evaluates against the original PRD, human gives final sign-off. Shows both patterns: external PRD file referenced in prompts, and PRD generated by early pipeline stages.

15. **The Complete Pipeline** — full .dot file for the task management API pipeline. All concepts from chapters 1-14 in one working example. Rendered graph as visualization.

---

## Cookbook (`docs/cookbook.md`)

**Title:** "Pipeline Patterns"

Each recipe: problem statement, complete .dot file, explanation, "try it" command. Grouped by category.

### Basic Patterns
- Linear pipeline (plan → implement → exit)
- Pipeline with a goal and prompt templates
- Dry-run for testing pipeline structure

### Branching & Routing
- Binary decision (success/fail paths)
- Multi-way branch (3+ outcomes from conditional)
- Weighted edges for priority routing
- Preferred label matching (LLM suggests which edge)
- Condition expressions with context variables

### Human-in-the-Loop
- Single approval gate (approve/reject)
- Multi-option review (approve, revise, escalate, reject)
- Accelerator keys for faster input (`[A] Approve`, `[R] Reject`)
- Recording decisions for audit trails

### Iteration & Retry
- Revise-and-resubmit loop (review → revise → re-review)
- Retry with backoff (`max_retries`)
- Goal gate enforcement (must-pass check before exit)
- `allow_partial` for best-effort nodes
- `loop_restart` for full pipeline reset

### Evaluation & Quality
- LLM-as-judge evaluation node
- Multi-stage validation chain (lint → test → LLM review → human review)
- Goal gate with retry loop
- Fidelity control for evaluation nodes (full context for the judge)
- Model stylesheet for evaluation (stronger model as judge)

### PRDs & Design Specs
- Feeding an external PRD into a pipeline (file path in prompt)
- Pipeline that generates a PRD from a goal statement
- Full lifecycle: Goal → PRD → Design → Implement → Validate → Exit
- Human review of generated PRD before implementation
- Iterating on a design spec (review → revise loop with goal gate)

### Parallel Execution
- Fan-out / fan-in (parallel branches, collect results)
- K-of-N join (proceed when 2 of 3 succeed)
- First-success join (take fastest branch)
- Error policy: fail-fast vs. continue

### Configuration & Scaling
- Model stylesheet with all three selector types
- Subgraph classes for grouping nodes
- Context fidelity modes
- Thread IDs for conversation continuity

### Operations
- Checkpoint and resume after crash
- HTTP server with SSE event monitoring
- Custom codergen backend integration
- Validation and linting before execution

---

## Concepts (`docs/concepts.md`)

**Title:** "How Attractor Works"

Explains the mental model. No code to copy — ideas and diagrams.

### Sections

1. **Pipelines Are Graphs** — nodes are stages, edges are transitions. Why graphs: visual, version-controllable, every path is explicit.

2. **Node Types and Handlers** — each shape triggers different behavior. Handler interface is pluggable. Swap backends without changing pipelines.

3. **Edge Routing** — the 5-step selection algorithm. Why conditions live on edges, not nodes.

4. **Outcomes and Status** — every node produces an Outcome (success, fail, partial_success, retry, skipped). Outcomes drive routing and carry context updates.

5. **The Context Store** — key-value store flowing through the pipeline. Namespace conventions. How stages communicate.

6. **Fidelity** — how much context carries forward. Modes: full, truncate, compact, summary. Precedence: edge > node > graph > default. Cost and speed trade-offs.

7. **Human-in-the-Loop** — the interviewer pattern. Choices derived from edges. Why it's edges, not a special property.

8. **Goal Gates** — nodes that must succeed before exit. Enforcement at the exit node. Jump-back via retry_target.

9. **Evaluation and Validation** — static validation (graph structure, before execution) vs. runtime evaluation (goal gates, condition expressions, LLM-as-judge, during execution). How to build evaluation into pipeline design.

10. **PRDs, Design Specs, and Pipeline Inputs** — how external documents (PRDs, specs, requirements) feed into pipelines. Goal as lightweight PRD. Prompt templates referencing files. Generated specs as pipeline outputs that become inputs to later stages.

11. **Checkpoints and Recovery** — what gets saved, what doesn't. Resume semantics.

12. **Parallel Execution** — fan-out, context isolation, join policies, error policies.

13. **Model Stylesheet** — CSS-like config. Specificity. Why per-node config doesn't scale.

14. **Transforms** — parse → transform → validate → execute lifecycle. Variable expansion, stylesheet application, preamble synthesis.

15. **The Event Stream** — every action emits an event. Headless engine, separate presentation.

---

## Reference (`docs/reference.md`)

**Title:** "Attractor Reference"

Lookup tables. Organized for scanning.

### Sections

1. CLI Commands (all flags, defaults, examples)
2. Node Shapes (shape → handler mapping)
3. Node Attributes (every attribute, type, default, description)
4. Edge Attributes (same format)
5. Graph Attributes (goal, default_max_retry, retry_target, model_stylesheet, etc.)
6. Condition Expression Syntax (operators, special keys, AND, truthiness, examples)
7. Model Stylesheet Syntax (selectors, specificity, properties)
8. Fidelity Modes (each mode with behavior and when to use)
9. Outcome Statuses (each status with routing implications)
10. Interviewer Types (four implementations, constructor signatures)
11. Validation Rules (every rule, severity, trigger, how to fix)
12. Pipeline Events (every event kind with payload fields)
13. HTTP Server Endpoints (method, path, request/response, curl examples)
14. Context Namespace Conventions (reserved keys, naming custom keys)

---

## README Update

Update `README.md` to point at Tutorial as primary entry point, with links to all four docs. Keep the NLSpec links and "Building Your Own Attractor" section.
